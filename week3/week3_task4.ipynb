{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "sensitive-selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dedicated-nomination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузите файл classification.csv. В нем записаны истинные классы\n",
    "# объектов выборки (колонка true) и ответы некоторого\n",
    "# классификатора (колонка predicted).\n",
    "data = pd.read_csv('classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "starting-suggestion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43  0]\n",
      " [93 64]]\n",
      "43 0 93 64\n"
     ]
    }
   ],
   "source": [
    "# Заполните таблицу ошибок классификации:\n",
    "# Для этого подсчитайте величины TP, FP, FN и TN согласно их\n",
    "# определениям. Например, FP — это количество объектов, имеющих\n",
    "# класс 0, но отнесенных алгоритмом к классу 1. \n",
    "# Ответ в данном вопросе — четыре числа через пробел.\n",
    "classificationErr = np.array([[0, 0], [0, 0]])\n",
    "T_col = 0\n",
    "P_col = 1\n",
    "\n",
    "for a in data.values:\n",
    "    if a[T_col] == 1:\n",
    "        if a[P_col] == 1:\n",
    "            classificationErr[0][0] += 1\n",
    "        else:\n",
    "            classificationErr[1][0] += 1\n",
    "    else:\n",
    "        if a[P_col] == 1:\n",
    "            classificationErr[1][0] += 1\n",
    "        else:\n",
    "            classificationErr[1][1] += 1\n",
    "\n",
    "print(classificationErr)\n",
    "print (' '.join(map(lambda x: str(x[0])+' '+str(x[1]), classificationErr)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "handmade-scanning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54, 0.56, 0.42, 0.48]\n"
     ]
    }
   ],
   "source": [
    "#  Посчитайте основные метрики качества классификатора:\n",
    "# • Accuracy (доля верно угаданных) — sklearn.metrics.accuracy\n",
    "# • Precision (точность) — sklearn.metrics.accuracy.precision_score\n",
    "# • Recall (полнота) — sklearn.metrics.recall_score\n",
    "# • F-мера — sklearn.metrics.f1_score\n",
    "\n",
    "accuracy_val = []\n",
    "accuracy_val.append(round(accuracy_score(data['true'].values, data['pred'].values), 2))\n",
    "accuracy_val.append(round(precision_score(data['true'].values, data['pred'].values), 2))\n",
    "accuracy_val.append(round(recall_score(data['true'].values, data['pred'].values), 2))\n",
    "accuracy_val.append(round(f1_score(data['true'].values, data['pred'].values), 2))\n",
    "\n",
    "print(accuracy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "compliant-appearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "del classificationErr\n",
    "del accuracy_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "hired-insight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Имеется четыре обученных классификатора. В файле scores.csv \n",
    "# записаны истинные классы и значения степени \n",
    "# принадлежности положительному классу для каждого \n",
    "# классификатора на некоторой выборке:\n",
    "# • для логистической регрессии — вероятность положительного\n",
    "# класса (колонка score_logreg),\n",
    "# • для SVM — отступ от разделяющей поверхности (колонка score_svm)\n",
    "# • для метрического алгоритма — взвешенная сумма классов \n",
    "# соседей (колонка score_knn),\n",
    "# • для решающего дерева — доля положительных объектов в\n",
    "# листе (колонка score_tree).\n",
    "\n",
    "data = pd.read_csv('scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "liable-shopper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     0\n",
      "score_logreg  0.719188\n"
     ]
    }
   ],
   "source": [
    "# Посчитайте площадь под ROC-кривой для каждого классификатора.\n",
    "# Какой классификатор имеет наибольшее значение метрики \n",
    "# AUC-ROC (укажите название столбца)?\n",
    "# Воспользуйтесь функцией sklearn.metrics.roc_auc_score.\n",
    "\n",
    "y_true = data['true'].values\n",
    "accuracy_val = {}\n",
    "accuracy_val['score_logreg'] = roc_auc_score(y_true, data['score_logreg'].values)\n",
    "accuracy_val['score_svm'] = roc_auc_score(y_true, data['score_svm'].values)\n",
    "accuracy_val['score_knn'] = roc_auc_score(y_true, data['score_knn'].values)\n",
    "accuracy_val['score_tree'] = roc_auc_score(y_true, data['score_tree'].values)\n",
    "\n",
    "date_res = pd.DataFrame(data = accuracy_val, index = [0]).transpose()\n",
    "date_res.sort_values([0], inplace = True, ascending = [False])\n",
    "print(date_res.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "statistical-jamaica",
   "metadata": {},
   "outputs": [],
   "source": [
    "del accuracy_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "vital-english",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Какой классификатор достигает наибольшей точности (Precision)\n",
    "# при полноте (Recall) не менее 70% (укажите название \n",
    "# столбца с ответами этого классификатора)? Какое значение\n",
    "# точности при этом получается?\n",
    "\n",
    "# Чтобы получить ответ на этот вопрос, найдите все точки \n",
    "# precisionrecall-кривой с помощью функции \n",
    "# sklearn.metrics.precision_recall_curve.\n",
    "# Она возвращает три массива: precision, recall, thresholds. \n",
    "# В них записаны точность и полнота при определенных порогах, \n",
    "# указанных в массиве thresholds. Найдите максимальной значение \n",
    "# точности среди тех записей, для которых полнота не меньше, чем 0.7\n",
    "\n",
    "def calculate(y_true, y_scores):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_scores)\n",
    "    date_res = pd.DataFrame(data=precision, columns=['precision'])\n",
    "    date_res['recall'] = recall\n",
    "    date_res['precision_sel'] = date_res.apply(lambda x: 0 if x['recall'] < 0.7 else x['precision'], axis = 1)\n",
    "    date_res.sort_values(['precision_sel'], ascending = [False], inplace = True)\n",
    "    date_res = date_res.reset_index(drop = True)\n",
    "    \n",
    "    return date_res.loc[0, 'precision_sel']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "informed-geometry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   0\n",
      "score_tree  0.651786\n"
     ]
    }
   ],
   "source": [
    "accuracy_val = {}\n",
    "accuracy_val['score_logreg'] = calculate(y_true, data['score_logreg'].values)\n",
    "accuracy_val['score_svm'] = calculate(y_true, data['score_svm'].values)\n",
    "accuracy_val['score_knn'] = calculate(y_true, data['score_knn'].values)\n",
    "accuracy_val['score_tree'] = calculate(y_true, data['score_tree'].values)\n",
    "\n",
    "date_res = pd.DataFrame(data = accuracy_val, index = [0]).transpose()\n",
    "date_res.sort_values([0], inplace = True, ascending = [False])\n",
    "print(date_res.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "interracial-sister",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Таблица ошибок\n",
      "43 34 59 64\n",
      "Оценки качества\n",
      "0.54 0.56 0.42 0.48\n",
      "Наименование лучшего классификатора\n",
      "                     0\n",
      "score_logreg  0.719188\n",
      "-----\n",
      "Какой классификатор достигает наибольшей точности\n",
      "                   0\n",
      "score_tree  0.651786\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Mar  6 10:59:46 2017\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "#==============================================================================\n",
    "# Загрузите файл classification.csv. В нем записаны истинные классы объектов выборки (колонка true)\n",
    "# и ответы некоторого классификатора (колонка predicted).\n",
    "#==============================================================================\n",
    "data= pd.read_csv('classification.csv')\n",
    "\n",
    "\n",
    "#Заполните таблицу ошибок классификации\n",
    "#==============================================================================\n",
    "# Для этого подсчитайте величины TP, FP, FN и TN согласно их определениям.\n",
    "# Например, FP — это количество объектов, имеющих класс 0, но отнесенных алгоритмом к классу 1.\n",
    "# Ответ в данном вопросе — четыре числа через пробел.\n",
    "#==============================================================================\n",
    "classificationErrorMatrix=np.array([[0,0],[0,0]])\n",
    "trueCol=0\n",
    "predCol=1\n",
    "\n",
    "for dt in data.values:\n",
    "    if dt[trueCol]==1:\n",
    "        if dt[predCol]==1: classificationErrorMatrix[0][0]+=1\n",
    "        else: classificationErrorMatrix[1][0]+=1\n",
    "    else:\n",
    "        if dt[predCol]==1: classificationErrorMatrix[0][1]+=1\n",
    "        else: classificationErrorMatrix[1][1]+=1\n",
    "\n",
    "print ('Таблица ошибок')\n",
    "print (' '.join(map(lambda x: str(x[0])+' '+str(x[1]), classificationErrorMatrix)))\n",
    "#==============================================================================\n",
    "# Посчитайте основные метрики качества классификатора:\n",
    "# Accuracy (доля верно угаданных) — sklearn.metrics.accuracy_score\n",
    "# Precision (точность) — sklearn.metrics.precision_score\n",
    "# Recall (полнота) — sklearn.metrics.recall_score\n",
    "# F-мера — sklearn.metrics.f1_score\n",
    "#==============================================================================\n",
    "accuracy_values=[]\n",
    "accuracy_values.append(round(accuracy_score(data['true'].values,data['pred'].values),2))\n",
    "accuracy_values.append(round(precision_score(data['true'].values,data['pred'].values),2))\n",
    "accuracy_values.append(round(recall_score(data['true'].values,data['pred'].values),2))\n",
    "accuracy_values.append(round(f1_score(data['true'].values,data['pred'].values),2))\n",
    "\n",
    "print ('Оценки качества')\n",
    "print (' '.join(map(lambda x: str(x), accuracy_values)))\n",
    "\n",
    "\n",
    "del classificationErrorMatrix\n",
    "del accuracy_values\n",
    "\n",
    "#==============================================================================\n",
    "# Имеется четыре обученных классификатора. В файле scores.csv записаны истинные классы и значения степени принадлежности положительному классу для каждого классификатора на некоторой выборке:\n",
    "# для логистической регрессии — вероятность положительного класса (колонка score_logreg),\n",
    "# для SVM — отступ от разделяющей поверхности (колонка score_svm),\n",
    "# для метрического алгоритма — взвешенная сумма классов соседей (колонка score_knn),\n",
    "# для решающего дерева — доля положительных объектов в листе (колонка score_tree).\n",
    "# Загрузите этот файл.\n",
    "#==============================================================================\n",
    "data= pd.read_csv('scores.csv')\n",
    "\n",
    "#==============================================================================\n",
    "# Посчитайте площадь под ROC-кривой для каждого классификатора.\n",
    "# Какой классификатор имеет наибольшее значение метрики AUC-ROC (укажите название столбца)?\n",
    "# Воспользуйтесь функцией sklearn.metrics.roc_auc_score.\n",
    "#==============================================================================\n",
    "def computeAUCROC(y_true,y_score):\n",
    "    return roc_auc_score(y_true,y_score)\n",
    "\n",
    "y_true=data['true'].values\n",
    "accuracy_values={}\n",
    "accuracy_values['score_logreg']=roc_auc_score(y_true,data['score_logreg'].values)\n",
    "accuracy_values['score_svm']=roc_auc_score(y_true,data['score_svm'].values)\n",
    "accuracy_values['score_knn']=roc_auc_score(y_true,data['score_knn'].values)\n",
    "accuracy_values['score_tree']=roc_auc_score(y_true,data['score_tree'].values)\n",
    "\n",
    "dt=pd.DataFrame(data=accuracy_values,index=[0]).transpose()\n",
    "dt.sort_values([0], ascending=[False],inplace=True)\n",
    "print('Наименование лучшего классификатора')\n",
    "print(dt.head(1))\n",
    "print('-----')\n",
    "del accuracy_values\n",
    "\n",
    "#==============================================================================\n",
    "# Какой классификатор достигает наибольшей точности (Precision) при полноте (Recall) не менее 70% ?\n",
    "# Чтобы получить ответ на этот вопрос, найдите все точки precision-recall-кривой с помощью функции\n",
    "# sklearn.metrics.precision_recall_curve. Она возвращает три массива: precision, recall, thresholds.\n",
    "# В них записаны точность и полнота при определенных порогах, указанных в массиве thresholds.\n",
    "# Найдите максимальной значение точности среди тех записей, для которых полнота не меньше, чем 0.7.\n",
    "#==============================================================================\n",
    "def CalculateThresholds(y_true,y_scores):\n",
    "    precision, recall, thresholds=precision_recall_curve(y_true,y_scores)\n",
    "    dt=pd.DataFrame(data=precision, columns=['precision'])#Создаем датафрейм\n",
    "    dt['recall']=recall#добавляем колонку\n",
    "    dt['precision_sel']=dt.apply(lambda x: 0 if x['recall']<0.7 else x['precision'],axis=1)#выкидываем лишние записи из точности по фильтру полноты\n",
    "    dt.sort_values(['precision_sel'], ascending=[False],inplace=True)#сортируем по точности\n",
    "    dt=dt.reset_index(drop=True)#реиндексируем\n",
    "    return dt.loc[0,'precision_sel']#выбираем максимум точности\n",
    "\n",
    "accuracy_values={}\n",
    "accuracy_values['score_logreg']=CalculateThresholds(y_true,data['score_logreg'].values)\n",
    "accuracy_values['score_svm']=CalculateThresholds(y_true,data['score_svm'].values)\n",
    "accuracy_values['score_knn']=CalculateThresholds(y_true,data['score_knn'].values)\n",
    "accuracy_values['score_tree']=CalculateThresholds(y_true,data['score_tree'].values)\n",
    "\n",
    "dt=pd.DataFrame(data=accuracy_values,index=[0]).transpose()\n",
    "dt.sort_values([0], ascending=[False],inplace=True)\n",
    "print('Какой классификатор достигает наибольшей точности')\n",
    "print(dt.head(1))\n",
    "print('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-chick",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
